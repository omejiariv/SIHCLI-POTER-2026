import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from sqlalchemy import create_engine, text
import sys
import os
import rasterio
from rasterio.transform import from_origin
import io
from prophet import Prophet
from datetime import datetime
from dateutil.relativedelta import relativedelta

# --- IMPORTS MODULARES ---
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from modules import analysis, selectors, interpolation, data_processor
from modules import land_cover as lc
from modules.config import Config

st.set_page_config(page_title="Aguas Subterr√°neas", page_icon="üíß", layout="wide")

# --- METODOLOG√çA COMPLETA (SOLICITUD 3) ---
with st.expander("‚ÑπÔ∏è Metodolog√≠a, Conceptos e Interpretaci√≥n (Detallado)", expanded=False):
    st.markdown("""
    ### 1. Marco Conceptual
    Este m√≥dulo estima la **Recarga Potencial de Acu√≠feros**, definida como la l√°mina de agua que logra infiltrarse a trav√©s del suelo y llegar a la zona saturada, convirti√©ndose en agua subterr√°nea renovable.

    ### 2. Metodolog√≠a de C√°lculo
    Se utiliza un enfoque de **Balance H√≠drico Mensual** agregados anualmente, basado en la f√≥rmula de **Turc (1954)** modificado para zonas tropicales:
    
    * **P (Precipitaci√≥n):** Variable de entrada principal (mm).
    * **T (Temperatura):** Estimada mediante gradiente altitudinal (-0.6¬∞C / 100m) o datos directos.
    * **L(t) (Capacidad Evaporante):** $L(t) = 300 + 25T + 0.05T^3$.
    * **ETR (Evapotranspiraci√≥n Real):** $ETR = \frac{P}{\sqrt{0.9 + (P/L)^2}}$. Representa el agua que regresa a la atm√≥sfera por evaporaci√≥n del suelo y transpiraci√≥n de plantas.
    * **Excedente H√≠drico (Q):** $Q = P - ETR$. Es el agua l√≠quida disponible en superficie.
    * **Recarga (R):** $R = Q \times C_{inf}$. Donde $C_{inf}$ es el Coeficiente de Infiltraci√≥n, que depende de la cobertura del suelo (Bosque, Pastos, Urbano) y la permeabilidad geol√≥gica.

    ### 3. Pron√≥stico Hidrol√≥gico (Inteligencia Artificial)
    Para proyectar la serie hacia el futuro, se utiliza el modelo **Prophet (Meta AI)** con configuraci√≥n avanzada:
    * **Estacionalidad:** Modelo multiplicativo anual (captura bimodalidad de lluvias andinas).
    * **Regresores Externos:** El modelo se entrena considerando √≠ndices clim√°ticos globales (**ONI/Ni√±o, SOI, IOD**) para capturar la variabilidad macroclim√°tica.
    * **Simulaci√≥n Estoc√°stica:** Se inyecta ruido estad√≠stico basado en la varianza hist√≥rica para simular escenarios realistas de extremos (no solo promedios).

    ### 4. Modelo Espacial (Geoestad√≠stica)
    La distribuci√≥n espacial se realiza mediante interpolaci√≥n **RBF (Radial Basis Functions)** sobre las estaciones monitoreadas, generando una superficie continua (Raster) de precipitaci√≥n y recarga, corregida por topograf√≠a y cobertura del suelo.
    
    ### 5. Interpretaci√≥n
    * **Mapas Azules Oscuros:** Zonas de alta recarga (Estrat√©gicas para protecci√≥n).
    * **Brecha P vs ETR:** En a√±os secos (Ni√±o), la ETR puede consumir casi toda la precipitaci√≥n, llevando la recarga a cero.
    """)

st.title("üíß Estimaci√≥n de Recarga (Modelo Turc + Escenarios)")

# --- 1. CONFIGURACI√ìN ---
ids_seleccionados, nombre_seleccion, altitud_ref, gdf_zona = selectors.render_selector_espacial()

with st.sidebar:
    st.divider()
    st.subheader("ü§ñ Pron√≥stico & Escenarios")
    usar_forecast = st.checkbox("Activar Proyecci√≥n", value=True)
    
    meses_futuros = 12
    usar_estocastico = False
    
    if usar_forecast:
        meses_futuros = st.selectbox("Horizonte (meses):", [12, 24, 36, 60], index=1)
        st.markdown("**Configuraci√≥n del Modelo:**")
        usar_estocastico = st.checkbox("üé≤ Simular Variabilidad Real", value=True, help="A√±ade ruido estad√≠stico para simular picos y valles.")
        
        if usar_estocastico:
            nivel_ruido = st.slider("Intensidad Variabilidad:", 0.5, 1.5, 1.0)

    st.divider()
    st.subheader("Parametrizaci√≥n Suelo")
    
    # Coeficiente Inteligente
    coef_default = 0.30
    if gdf_zona is not None and not gdf_zona.empty:
        try:
            stats = lc.calculate_cover_stats(gdf_zona, Config.LAND_COVER_RASTER_PATH)
            if stats:
                c_sug, razon = lc.get_infiltration_suggestion(stats)
                coef_default = c_sug
                st.caption(f"‚ú® IA Cobertura: {razon}")
        except: pass

    coef_final = st.slider("Coef. Infiltraci√≥n", 0.0, 1.0, float(coef_default))
    temp_estimada = analysis.estimate_temperature(altitud_ref)

# --- FUNCI√ìN AUXILIAR RASTER ---
def get_geotiff_bytes(grid_data, transform, crs):
    mem_file = io.BytesIO()
    with rasterio.open(
        mem_file, 'w', driver='GTiff',
        height=grid_data.shape[0], width=grid_data.shape[1],
        count=1, dtype=grid_data.dtype, crs=crs, transform=transform,
    ) as dst:
        dst.write(grid_data, 1)
    return mem_file.getvalue()

# --- 2. MOTOR DE C√ÅLCULO ---
if ids_seleccionados:
    engine = create_engine(st.secrets["DATABASE_URL"])
    ids_sql = str(tuple(ids_seleccionados)).replace(',)', ')')
    
    q = f"""
        SELECT fecha_mes_a√±o AS fecha, precipitation AS valor, id_estacion_fk AS id_estacion
        FROM precipitacion_mensual 
        WHERE id_estacion_fk IN {ids_sql}
        ORDER BY fecha_mes_a√±o
    """
    
    with engine.connect() as conn:
        df_precip = pd.read_sql(text(q), conn)
        
    if not df_precip.empty:
        df_precip['fecha'] = pd.to_datetime(df_precip['fecha'])
        
        # --- CARGA CLIMA Y METADATOS ---
        try:
            all_data = data_processor.load_and_process_all_data()
            gdf_stations = all_data[0]
            df_climatico = all_data[3]
            if not df_climatico.empty:
                df_climatico['fecha_mes_a√±o'] = pd.to_datetime(df_climatico['fecha_mes_a√±o'])
            
            # MERGE COMPLETO (SOLICITUD 2 - Asegurar columnas)
            cols_meta = ['id_estacion', 'latitude', 'longitude', 'nom_est', 'municipio', 'alt_est']
            cols_existentes = [c for c in cols_meta if c in gdf_stations.columns]
            df_full = pd.merge(df_precip, gdf_stations[cols_existentes], on='id_estacion', how='left')
        except:
            df_full = df_precip
            df_climatico = pd.DataFrame()

        tab1, tab2 = st.tabs(["üìâ An√°lisis Temporal y Pron√≥stico", "üó∫Ô∏è Mapa de Recarga Distribuida"])
        
        # === TAB 1 ===
        with tab1:
            st.markdown(f"##### Din√°mica Hist√≥rica y Escenarios: {nombre_seleccion}")
            
            # 1. Agrupaci√≥n
            df_ts_monthly = df_full.groupby('fecha')['valor'].mean().reset_index()
            
            # Merge Clima
            if not df_climatico.empty:
                df_ts_monthly = pd.merge(df_ts_monthly, df_climatico, left_on='fecha', right_on='fecha_mes_a√±o', how='left')
                cols_clima = ['anomalia_oni', 'soi', 'iod']
                cols_clima_presentes = [c for c in cols_clima if c in df_ts_monthly.columns]
                if cols_clima_presentes:
                    df_ts_monthly[cols_clima_presentes] = df_ts_monthly[cols_clima_presentes].fillna(0)
            
            # Filtro Calidad
            df_ts_monthly['a√±o_temp'] = df_ts_monthly['fecha'].dt.year
            annual_stats = df_ts_monthly.groupby('a√±o_temp')['valor'].sum()
            threshold = annual_stats.mean() * 0.5
            years_to_drop = annual_stats[annual_stats < threshold].index.tolist()
            
            df_train = df_ts_monthly.copy()
            if years_to_drop:
                df_train = df_ts_monthly[~df_ts_monthly['a√±o_temp'].isin(years_to_drop)]
            
            df_final_ts = df_ts_monthly.drop(columns=['a√±o_temp', 'fecha_mes_a√±o'], errors='ignore').copy()
            df_final_ts['tipo'] = 'Hist√≥rico'
            df_final_ts['yhat_lower'] = df_final_ts['valor']
            df_final_ts['yhat_upper'] = df_final_ts['valor']

            # 2. PROPHET
            if usar_forecast and len(df_train) > 24:
                with st.spinner("üß† Generando escenarios hidrol√≥gicos..."):
                    try:
                        last_hist_date = df_train['fecha'].max()
                        df_prophet = df_train.rename(columns={'fecha': 'ds', 'valor': 'y'})
                        
                        m = Prophet(
                            seasonality_mode='multiplicative', 
                            yearly_seasonality=True,
                            changepoint_prior_scale=0.5
                        )
                        
                        cols_clima_usadas = []
                        if 'anomalia_oni' in df_prophet.columns:
                            m.add_regressor('anomalia_oni')
                            cols_clima_usadas.append('anomalia_oni')
                            
                        m.fit(df_prophet)
                        
                        # Horizonte
                        fecha_objetivo = datetime.now() + relativedelta(months=meses_futuros)
                        future = m.make_future_dataframe(periods=300, freq='MS')
                        future = future[future['ds'] <= fecha_objetivo]
                        
                        if cols_clima_usadas:
                            last_indices = df_ts_monthly.sort_values('fecha').iloc[-1][cols_clima_usadas]
                            for col in cols_clima_usadas: future[col] = last_indices[col]
                        
                        forecast = m.predict(future)
                        
                        df_future = forecast[forecast['ds'] > last_hist_date][['ds', 'yhat', 'yhat_lower', 'yhat_upper']].rename(columns={'ds': 'fecha', 'yhat': 'valor'})
                        df_future['tipo'] = 'Pron√≥stico'
                        
                        if usar_estocastico:
                            residuals = df_prophet['y'] - forecast.loc[forecast['ds'].isin(df_prophet['ds']), 'yhat']
                            std_resid = residuals.std()
                            np.random.seed(42)
                            noise = np.random.normal(0, std_resid * nivel_ruido, len(df_future))
                            df_future['valor'] += noise
                            df_future['yhat_upper'] += (std_resid * nivel_ruido)
                            df_future['yhat_lower'] -= (std_resid * nivel_ruido)

                        df_future['valor'] = df_future['valor'].clip(lower=0)
                        df_future['yhat_lower'] = df_future['yhat_lower'].clip(lower=0)
                        for col in cols_clima_usadas: df_future[col] = 0

                        df_final_ts = pd.concat([df_final_ts, df_future], ignore_index=True)
                        st.success(f"‚úÖ Escenario generado hasta {fecha_objetivo.date()}.")
                    except Exception as e:
                        st.error(f"Error: {e}")

            # 3. Balance Anual
            df_final_ts['a√±o'] = df_final_ts['fecha'].dt.year
            df_anual = df_final_ts.groupby(['a√±o', 'tipo']).agg({'valor': 'sum', 'yhat_lower': 'sum', 'yhat_upper': 'sum'}).reset_index()
            
            turc_res = df_anual.apply(lambda x: analysis.calculate_water_balance_turc(x['valor'], temp_estimada), axis=1)
            df_anual['etr'] = [x[0] for x in turc_res]
            df_anual['recarga'] = np.array([x[1] for x in turc_res]) * coef_final
            
# --- SOLUCI√ìN SIERRA: UNIFICAR DATOS PARA L√çNEAS ---
            # Agrupamos SOLO por a√±o para tener una serie continua sin duplicados de transici√≥n
            df_lines = df_anual.groupby('a√±o').agg({
                'etr': 'sum',
                'recarga': 'sum'
            }).reset_index().sort_values('a√±o')
            
            # --- GR√ÅFICO ---
            fig_t = go.Figure()
            
            hist = df_anual[df_anual['tipo'] == 'Hist√≥rico']
            pred = df_anual[df_anual['tipo'] == 'Pron√≥stico']
            
            # 1. Intervalo Confianza
            if not pred.empty:
                fig_t.add_trace(go.Scatter(
                    x=pd.concat([pred['a√±o'], pred['a√±o'][::-1]]),
                    y=pd.concat([pred['yhat_upper'], pred['yhat_lower'][::-1]]),
                    fill='toself', fillcolor='rgba(173, 216, 230, 0.2)',
                    line=dict(color='rgba(255,255,255,0)'), name='Rango Incertidumbre'
                ))

            # 2. Barras Hist√≥ricas
            fig_t.add_trace(go.Bar(x=hist['a√±o'], y=hist['valor'], name='Precipitaci√≥n Hist√≥rica', marker_color='#87CEEB'))
            
            # 3. Barras Pron√≥stico (RESTAURADO A BARRAS)
            if not pred.empty:
                fig_t.add_trace(go.Bar(
                    x=pred['a√±o'], y=pred['valor'], 
                    name='Precipitaci√≥n Proyectada', 
                    marker_color='#ADD8E6', 
                    marker_line_color='#4682B4', 
                    marker_line_width=1.5, 
                    opacity=0.7
                ))
            # 4. L√≠neas Balance (USANDO df_lines UNIFICADO = NO M√ÅS SIERRA)
            fig_t.add_trace(go.Scatter(
                x=df_lines['a√±o'], y=df_lines['etr'], 
                name='ETR', 
                line=dict(color='#FFA500', width=2, dash='dot', shape='spline', smoothing=1.3)
            ))
            
            fig_t.add_trace(go.Scatter(
                x=df_lines['a√±o'], y=df_lines['recarga'], 
                name='Recarga', 
                line=dict(color='#00008B', width=3, shape='spline', smoothing=1.3)
            ))

            fig_t.update_layout(title="Din√°mica Hidrol√≥gica", hovermode="x unified", legend=dict(orientation="h", y=1.1))
            st.plotly_chart(fig_t, use_container_width=True)
            
            with st.expander("üìÑ Tabla de Datos", expanded=False):
                format_dict = {'valor': "{:,.1f}", 'etr': "{:,.1f}", 'recarga': "{:,.1f}"}
                st.dataframe(df_anual[['a√±o', 'tipo', 'valor', 'etr', 'recarga']].style.format(format_dict))
                st.download_button("üíæ Descargar CSV", df_anual.to_csv(index=False).encode('utf-8'), f"balance_{nombre_seleccion}.csv")

        # === TAB 2: MAPA ===
        with tab2:
            st.markdown(f"##### Modelo Espacial: {nombre_seleccion}")
            if 'longitude' in df_full.columns and gdf_zona is not None:
                # SOLICITUD 2: Agrupaci√≥n expl√≠cita con Municipio/Altura para que no se pierdan
                cols_grp = ['id_estacion', 'nom_est', 'longitude', 'latitude']
                # Verificamos y agregamos columnas opcionales al groupby
                for col in ['municipio', 'alt_est']:
                    if col in df_full.columns: cols_grp.append(col)
                
                df_spatial = df_full.groupby(cols_grp)['valor'].mean().reset_index()
                df_spatial['valor_anual'] = df_spatial['valor'] * 12
                
                L_t = 300 + 25*temp_estimada + 0.05*(temp_estimada**3)
                def calc_pt(ppt):
                    with np.errstate(divide='ignore'): etr = ppt / np.sqrt(0.9 + (ppt/L_t)**2)
                    return min(etr, ppt), (ppt - min(etr, ppt)) * coef_final
                
                df_spatial['etr_pt'], df_spatial['rec_pt'] = zip(*df_spatial['valor_anual'].apply(calc_pt))
                
                # Popup Restaurado
                def build_popup(row):
                    muni = row['municipio'] if 'municipio' in row else 'N/D'
                    alt = f"{row['alt_est']:.0f}" if 'alt_est' in row and pd.notnull(row['alt_est']) else "N/D"
                    return (
                        f"<b>{row['nom_est']}</b><br>"
                        f"üèôÔ∏è {muni} | ‚õ∞Ô∏è {alt} msnm<br>"
                        f"üåßÔ∏è P: {row['valor_anual']:.0f}<br>"
                        f"‚òÄÔ∏è ETR: {row['etr_pt']:.0f}<br>"
                        f"üíß <b>R: {row['rec_pt']:.0f}</b>"
                    )
                df_spatial['hover_txt'] = df_spatial.apply(build_popup, axis=1)

                if len(df_spatial) >= 3:
                    bounds = gdf_zona.total_bounds
                    gx, gy = interpolation.generate_grid_coordinates((bounds[0], bounds[2], bounds[1], bounds[3]), resolution=100j)
                    grid_P = interpolation.interpolate_spatial(df_spatial, 'valor_anual', gx, gy, method='rbf')
                    
                    if grid_P is not None:
                        grid_R = (grid_P - (grid_P / np.sqrt(0.9 + (grid_P/L_t)**2))) * coef_final
                        grid_R = np.nan_to_num(grid_R, nan=0.0)
                        
                        fig_map = go.Figure()
                        fig_map.add_trace(go.Contour(
                            z=grid_R.T, x=gx[:,0], y=gy[0,:],
                            colorscale="Blues", name="Recarga (mm)",
                            colorbar=dict(title="mm/a√±o", len=0.6, y=-0.2, orientation='h'), showscale=True
                        ))
                        
                        candidates = ['nombre', 'subcuenca', 'name', 'microcuenca']
                        col_name_sub = next((c for c in gdf_zona.columns if any(x in c.lower() for x in candidates)), None)
                        for idx, row in gdf_zona.iterrows():
                            geom = row.geometry
                            name_sub = row[col_name_sub] if col_name_sub else ""
                            if geom.geom_type == 'Polygon': polys = [geom]
                            elif geom.geom_type == 'MultiPolygon': polys = geom.geoms
                            else: polys = []
                            for poly in polys:
                                x, y = poly.exterior.xy
                                fig_map.add_trace(go.Scatter(
                                    x=list(x), y=list(y), mode='lines', line=dict(color='black', width=1),
                                    name=str(name_sub), text=f"Zona: {name_sub}", hoverinfo='text', showlegend=False
                                ))

                        fig_map.add_trace(go.Scatter(
                            x=df_spatial['longitude'], y=df_spatial['latitude'],
                            mode='markers', marker=dict(color='red', size=6, line=dict(color='white', width=1)),
                            text=df_spatial['hover_txt'], hoverinfo='text', name="Estaciones"
                        ))
                        
                        fig_map.update_layout(height=650, margin=dict(t=10, b=80, l=0, r=0), xaxis=dict(visible=False), yaxis=dict(visible=False, scaleanchor="x"))
                        st.plotly_chart(fig_map, use_container_width=True)
                        
                        c1, c2 = st.columns(2)
                        tiff = get_geotiff_bytes(np.flipud(grid_R.T), from_origin(gx[0,0], gy[0,-1], gx[1,0]-gx[0,0], gy[0,0]-gy[0,1]), "EPSG:4326")
                        c1.download_button("üíæ Raster (TIF)", tiff, f"recarga_{nombre_seleccion}.tif")
                        c2.download_button("üìÑ Estaciones (CSV)", df_spatial.drop(columns=['hover_txt']).to_csv(index=False), f"estaciones_{nombre_seleccion}.csv")
                    else: st.warning("Error interpolando.")
                else: st.warning("M√≠nimo 3 estaciones.")
    else: st.warning("Sin datos.")